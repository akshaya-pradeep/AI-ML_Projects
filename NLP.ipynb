{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIDMkDx6jH6wlfVM0WxOWF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"zUjBWWyxglBv","executionInfo":{"status":"ok","timestamp":1733499299825,"user_tz":-330,"elapsed":452,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}}},"outputs":[],"source":["# For NLP we use a package â€”> nltk [Natural Language Tool Kit]\n","import nltk"]},{"cell_type":"code","source":["help(nltk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBZqpNZphK80","executionInfo":{"status":"ok","timestamp":1733499300309,"user_tz":-330,"elapsed":21,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"c3eb74d1-ca92-4981-fd7e-b542b5564bc9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package nltk:\n","\n","NAME\n","    nltk\n","\n","DESCRIPTION\n","    The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing.  A free online book is available.\n","    (If you use the library for academic research, please cite the book.)\n","    \n","    Steven Bird, Ewan Klein, and Edward Loper (2009).\n","    Natural Language Processing with Python.  O'Reilly Media Inc.\n","    https://www.nltk.org/book/\n","    \n","    isort:skip_file\n","    \n","    @version: 3.9.1\n","\n","PACKAGE CONTENTS\n","    app (package)\n","    book\n","    ccg (package)\n","    chat (package)\n","    chunk (package)\n","    classify (package)\n","    cli\n","    cluster (package)\n","    collections\n","    collocations\n","    compat\n","    corpus (package)\n","    data\n","    decorators\n","    downloader\n","    draw (package)\n","    featstruct\n","    grammar\n","    help\n","    inference (package)\n","    internals\n","    jsontags\n","    langnames\n","    lazyimport\n","    lm (package)\n","    metrics (package)\n","    misc (package)\n","    parse (package)\n","    probability\n","    sem (package)\n","    sentiment (package)\n","    stem (package)\n","    tabdata\n","    tag (package)\n","    tbl (package)\n","    test (package)\n","    text\n","    tgrep\n","    tokenize (package)\n","    toolbox\n","    translate (package)\n","    tree (package)\n","    treeprettyprinter\n","    treetransforms\n","    twitter (package)\n","    util\n","    wsd\n","\n","SUBMODULES\n","    agreement\n","    aline\n","    api\n","    arlstem\n","    arlstem2\n","    association\n","    bleu_score\n","    bllip\n","    boxer\n","    brill\n","    brill_trainer\n","    casual\n","    chart\n","    chrf_score\n","    cistem\n","    confusionmatrix\n","    corenlp\n","    crf\n","    decisiontree\n","    dependencygraph\n","    destructive\n","    discourse\n","    distance\n","    drt\n","    earleychart\n","    evaluate\n","    featurechart\n","    gale_church\n","    gdfa\n","    gleu_score\n","    glue\n","    hmm\n","    hunpos\n","    ibm1\n","    ibm2\n","    ibm3\n","    ibm4\n","    ibm5\n","    ibm_model\n","    isri\n","    lancaster\n","    legality_principle\n","    lfg\n","    linearlogic\n","    logic\n","    mace\n","    malt\n","    mapping\n","    maxent\n","    megam\n","    meteor_score\n","    mwe\n","    naivebayes\n","    named_entity\n","    nist_score\n","    nonprojectivedependencyparser\n","    paice\n","    pchart\n","    perceptron\n","    phrase_based\n","    porter\n","    positivenaivebayes\n","    projectivedependencyparser\n","    prover9\n","    punkt\n","    recursivedescent\n","    regexp\n","    relextract\n","    repp\n","    resolution\n","    ribes_score\n","    rslp\n","    rte_classify\n","    scikitlearn\n","    scores\n","    segmentation\n","    senna\n","    sequential\n","    sexpr\n","    shiftreduce\n","    simple\n","    snowball\n","    sonority_sequencing\n","    spearman\n","    stack_decoder\n","    stanford\n","    stanford_segmenter\n","    tableau\n","    tadm\n","    textcat\n","    texttiling\n","    tnt\n","    toktok\n","    transitionparser\n","    treebank\n","    viterbi\n","    weka\n","    wordnet\n","\n","FUNCTIONS\n","    demo()\n","        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n","    \n","    tee(iterable, n=2, /)\n","        Returns a tuple of n independent iterators.\n","\n","DATA\n","    PRETRAINED_TAGGERS = {'eng': 'taggers/averaged_perceptron_tagger_eng/'...\n","    SLASH = *slash*\n","    TYPE = *type*\n","    __author_email__ = 'nltk.team@gmail.com'\n","    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n","    __copyright__ = 'Copyright (C) 2001-2024 NLTK Project.\\n\\nDistribut......\n","    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n","    __license__ = 'Apache License, Version 2.0'\n","    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...LT...\n","    __maintainer__ = 'NLTK Team'\n","    __maintainer_email__ = 'nltk.team@gmail.com'\n","    __url__ = 'https://www.nltk.org/'\n","    app = <LazyModule 'nltk.app'>\n","    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n","    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n","    version_file = '/usr/local/lib/python3.10/dist-packages/nltk/VERSION'\n","\n","VERSION\n","    3.9.1\n","\n","AUTHOR\n","    NLTK Team\n","\n","FILE\n","    /usr/local/lib/python3.10/dist-packages/nltk/__init__.py\n","\n","\n"]}]},{"cell_type":"markdown","source":["How to identify stop words"],"metadata":{"id":"Aglre8QShZBV"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop=stopwords.words('english')\n","stop\n","\n","# for nlp we need to dowload the resourse first otherwise the code will show error like this\n","# Resource stopwords not found.\n","# Please use the NLTK Downloader to obtain the resource:\n","# >>> import nltk\n","# >>> nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oReL7QmQhcBy","executionInfo":{"status":"ok","timestamp":1733499300310,"user_tz":-330,"elapsed":17,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"4d47b2aa-6707-4d5b-ca20-bec334144408"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# no.of stop words in that list\n","print(len(stop))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QcxhbJHmihpx","executionInfo":{"status":"ok","timestamp":1733499300310,"user_tz":-330,"elapsed":13,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"6b32eee0-8cb1-46d6-de74-ecfa01b074da"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["179\n"]}]},{"cell_type":"markdown","source":["## Tokenization"],"metadata":{"id":"El3bgMnyi1uE"}},{"cell_type":"code","source":["# if there are single line of sentence we can pass it through single quote('').\n","# But if there are multiple lines then we use triple qoute(''' ''')\n","nltk.download('punkt_tab')\n","sentence = 'luminar technolab is IT finishing school located at kakkanad'\n","from nltk.tokenize import word_tokenize\n","tok=word_tokenize(sentence)\n","tok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kdgx_s7vi1H6","executionInfo":{"status":"ok","timestamp":1733499300310,"user_tz":-330,"elapsed":11,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"84f1a91e-18e6-4f92-cbf6-53b5cae10c41"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["['luminar',\n"," 'technolab',\n"," 'is',\n"," 'IT',\n"," 'finishing',\n"," 'school',\n"," 'located',\n"," 'at',\n"," 'kakkanad']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["review='''The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing. A free online book is available'''\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","Stop=stopwords.words('english')\n","review_token=word_tokenize(review)\n","# stop_removed=[i for i in review_token if i not in Stop]\n","# stop_removed # some stop words are removed and some are not (eg: The) because it is in capital letter. So we need to convert it into lowercase\n","final_removed=[i.lower() for i in review_token if i.lower() not in Stop]\n","final_removed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QswuJEKBkIbJ","executionInfo":{"status":"ok","timestamp":1733499367274,"user_tz":-330,"elapsed":735,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"6462304a-cc5e-4e6d-da8b-6afbae660766"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["['natural',\n"," 'language',\n"," 'toolkit',\n"," '(',\n"," 'nltk',\n"," ')',\n"," 'open',\n"," 'source',\n"," 'python',\n"," 'library',\n"," 'natural',\n"," 'language',\n"," 'processing',\n"," '.',\n"," 'free',\n"," 'online',\n"," 'book',\n"," 'available']"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## N-gram"],"metadata":{"id":"p61AAK7uno7G"}},{"cell_type":"code","source":["from nltk.util import ngrams\n","sentence='this is very good book to study'\n","data=ngrams(sequence=word_tokenize(sentence),n=2)\n","for i in data:\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvS2MtAMnoo_","executionInfo":{"status":"ok","timestamp":1733499595935,"user_tz":-330,"elapsed":13,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"1c637293-88a0-4c64-f7b8-932bf8fdf69c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["('this', 'is')\n","('is', 'very')\n","('very', 'good')\n","('good', 'book')\n","('book', 'to')\n","('to', 'study')\n"]}]},{"cell_type":"markdown","source":["## Stemming\n","\n","\n","*   porterStemmer\n","*   SnowballStemmer\n","\n"],"metadata":{"id":"29RzVB8wohOi"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","po=PorterStemmer()\n","words=['programming','reached','walking','baked','running','sliced']\n","for i in words:\n","  print(i,\":\",po.stem(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ac1JyC2LojK6","executionInfo":{"status":"ok","timestamp":1733499946253,"user_tz":-330,"elapsed":784,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"493b1d67-db6b-4623-fc6d-31c5506697a5"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["programming : program\n","reached : reach\n","walking : walk\n","baked : bake\n","running : run\n","sliced : slice\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","sn=SnowballStemmer('english')\n","for i in words:\n","  print(i,':',sn.stem(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McUFWbVspsJd","executionInfo":{"status":"ok","timestamp":1733500051200,"user_tz":-330,"elapsed":622,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"a0356f81-bb97-4b7f-84ac-7946f025c38e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["programming : program\n","reached : reach\n","walking : walk\n","baked : bake\n","running : run\n","sliced : slice\n"]}]},{"cell_type":"markdown","source":["## Lemmatization\n","Lemmatization is most suitable for words that ends in 's'\n","\n","Either lemmatization or stemming need to be done\n","\n","Not both\n","\n","We use stemming for majority of cases, and it is more effective"],"metadata":{"id":"SFoy77TYp-1X"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","lem=WordNetLemmatizer()\n","print('rocks : ',lem.lemmatize('rocks'))\n","print('reaches : ',lem.lemmatize('reaches'))\n","print('walking : ',lem.lemmatize('walking'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR-IsmlKqKOG","executionInfo":{"status":"ok","timestamp":1733500329352,"user_tz":-330,"elapsed":449,"user":{"displayName":"AKSHAYA P","userId":"05752968279469929153"}},"outputId":"c1e6a07b-f295-4073-f7a2-d7ddf0324ff6"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks :  rock\n","reaches :  reach\n","walking :  walking\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]}]}